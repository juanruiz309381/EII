{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ IMPORTS ==============\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ CONFIGURACIÓN ==============\n",
    "IMG_SIZE = (48, 48)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "NUM_CLASSES = 7  # angry, disgust, fear, happy, sad, surprise, neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ PREPARACIÓN DE DATOS ==============\n",
    "def create_data_generators():\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        'train_dir',\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        color_mode='grayscale',\n",
    "        class_mode='categorical',\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    val_generator = train_datagen.flow_from_directory(\n",
    "        'train_dir',\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        color_mode='grayscale',\n",
    "        class_mode='categorical',\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ MODELO DESDE CERO ==============\n",
    "def create_cnn_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        \n",
    "        layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        \n",
    "        layers.Conv2D(128, (3,3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        \n",
    "        layers.Conv2D(256, (3,3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        \n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ TRANSFER LEARNING (VGG16) ==============\n",
    "def create_transfer_model():\n",
    "    base_model = VGG16(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(48,48,3)\n",
    "    )\n",
    "    \n",
    "    # Congelar capas base\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ FINE-TUNING ==============\n",
    "def create_fine_tuned_model():\n",
    "    base_model = VGG16(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(48,48,3)\n",
    "    )\n",
    "    \n",
    "    # Descongelar últimas capas\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ ENTRENAMIENTO ==============\n",
    "def train_model(model, train_gen, val_gen, model_name):\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7),\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_gen,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    model.save(f'{model_name}_emotion.h5')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ IMPLEMENTACIÓN EN TIEMPO REAL ==============\n",
    "class EmotionDetector:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = keras.models.load_model(model_path)\n",
    "        self.emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    def detect_emotion(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = self.face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "            face_roi = cv2.resize(face_roi, IMG_SIZE)\n",
    "            face_roi = face_roi.astype('float32') / 255.0\n",
    "            face_roi = np.expand_dims(face_roi, axis=(0, -1))\n",
    "            \n",
    "            # Para modelos que esperan entrada RGB\n",
    "            if self.model.input_shape[-1] == 3:\n",
    "                face_roi = np.repeat(face_roi, 3, axis=-1)\n",
    "            \n",
    "            prediction = self.model.predict(face_roi, verbose=0)\n",
    "            emotion_idx = np.argmax(prediction)\n",
    "            confidence = np.max(prediction)\n",
    "            \n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "            label = f\"{self.emotions[emotion_idx]} ({confidence:.2f})\"\n",
    "            cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def run_camera(self):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            frame = self.detect_emotion(frame)\n",
    "            cv2.imshow('Emotion Detection', frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ EJECUCIÓN PRINCIPAL ==============\n",
    "if __name__ == \"__main__\":\n",
    "    # Preparar datos\n",
    "    train_gen, val_gen = create_data_generators()\n",
    "    \n",
    "    # Entrenar diferentes modelos\n",
    "    models = {\n",
    "        'cnn': create_cnn_model(),\n",
    "        'transfer': create_transfer_model(),\n",
    "        'fine_tuned': create_fine_tuned_model()\n",
    "    }\n",
    "    \n",
    "    # Comparar modelos (ejecutar solo uno para ahorrar tiempo)\n",
    "    best_model = None\n",
    "    best_val_acc = 0\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nEntrenando {name}...\")\n",
    "        history = train_model(model, train_gen, val_gen, name)\n",
    "        \n",
    "        val_acc = max(history.history['val_accuracy'])\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model = name\n",
    "    \n",
    "    print(f\"\\nMejor modelo: {best_model} con val_accuracy: {best_val_acc:.4f}\")\n",
    "    \n",
    "    # Usar el mejor modelo para la cámara\n",
    "    detector = EmotionDetector(f'{best_model}_emotion.h5')\n",
    "    detector.run_camera()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-eii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
